{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if config exists\n",
    "try:\n",
    "    config\n",
    "except NameError:\n",
    "    config_exists = False\n",
    "else:\n",
    "    config_exists = True\n",
    "\n",
    "# make config if it does not exist already (e.g. passed in by papermill)\n",
    "if not(config_exists):\n",
    "    # set up some config for the experiment run\n",
    "    config = {\n",
    "        \"data_path\" : \"C:/Users/nico_/Desktop/ITBA/TFI/github/df_procesado/trollers_fe_recortado_v2.csv\",\n",
    "    }\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing core libraries\n",
    "#https://towardsdatascience.com/kagglers-guide-to-lightgbm-hyperparameter-tuning-with-optuna-in-2021-ed048d9838b5\n",
    "#https://www.kaggle.com/code/lucamassaron/tutorial-bayesian-optimization-with-lightgbm/notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import pprint\n",
    "import joblib\n",
    "from functools import partial\n",
    "\n",
    "# Suppressing warnings because of skopt verbosity\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Classifiers\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Skopt functions\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, DeltaYStopper\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# Data processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "df = pd.read_csv(config['data_path'], header=\"infer\", sep=\",\",error_bad_lines=False, engine ='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "['mmsi', 'timestamp', 'distance_from_shore', 'distance_from_port',\n",
    "       'speed', 'course', 'lat', 'lon', 'is_fishing', 'source', 'datetime',\n",
    "       'timediff', 'sun_state', 'distance', 'S0', 'A0', 'J0', 'C0', 'Vavg',\n",
    "       'Delta_S', 'Cavg', 'Delta_C', 'speed_lag_1', 'speed_lag_2',\n",
    "       'speed_lag_3', 'speed_lag_4', 'speed_lag_5', 'speed_lag_6',\n",
    "       'speed_lag_7', 'course_lag_1', 'course_lag_2', 'course_lag_3',\n",
    "       'course_lag_4', 'course_lag_5', 'course_lag_6', 'course_lag_7',\n",
    "       'S0_lag_1', 'S0_lag_2', 'S0_lag_3', 'S0_lag_4', 'S0_lag_5', 'S0_lag_6',\n",
    "       'S0_lag_7', 'A0_lag_1', 'A0_lag_2', 'A0_lag_3', 'A0_lag_4', 'A0_lag_5',\n",
    "       'A0_lag_6', 'A0_lag_7', 'J0_lag_1', 'J0_lag_2', 'J0_lag_3', 'J0_lag_4',\n",
    "       'J0_lag_5', 'J0_lag_6', 'J0_lag_7', 'C0_lag_1', 'C0_lag_2', 'C0_lag_3',\n",
    "       'C0_lag_4', 'C0_lag_5', 'C0_lag_6', 'C0_lag_7', 'Delta_C_lag_1',\n",
    "       'Delta_C_lag_2', 'Delta_C_lag_3', 'Delta_C_lag_4', 'Delta_C_lag_5',\n",
    "       'Delta_C_lag_6', 'Delta_C_lag_7', 'Delta_S_lag_1', 'Delta_S_lag_2',\n",
    "       'Delta_S_lag_3', 'Delta_S_lag_4', 'Delta_S_lag_5', 'Delta_S_lag_6',\n",
    "       'Delta_S_lag_7', 'Vavg_lag_1', 'Vavg_lag_2', 'Vavg_lag_3', 'Vavg_lag_4',\n",
    "       'Vavg_lag_5', 'Vavg_lag_6', 'Vavg_lag_7']\n",
    "'''\n",
    "df = df.drop(['mmsi', 'source','timestamp','source','datetime','distance_from_shore','distance_from_port'], axis = 1)\n",
    "lagged_columns =['distance', 'S0', 'A0', 'J0', 'C0', 'Vavg',\n",
    "       'Delta_S', 'Cavg', 'Delta_C', 'speed_lag_1', 'speed_lag_2',\n",
    "       'speed_lag_3', 'speed_lag_4', 'speed_lag_5', 'speed_lag_6',\n",
    "       'speed_lag_7', 'course_lag_1', 'course_lag_2', 'course_lag_3',\n",
    "       'course_lag_4', 'course_lag_5', 'course_lag_6', 'course_lag_7',\n",
    "       'S0_lag_1', 'S0_lag_2', 'S0_lag_3', 'S0_lag_4', 'S0_lag_5', 'S0_lag_6',\n",
    "       'S0_lag_7', 'A0_lag_1', 'A0_lag_2', 'A0_lag_3', 'A0_lag_4', 'A0_lag_5',\n",
    "       'A0_lag_6', 'A0_lag_7', 'J0_lag_1', 'J0_lag_2', 'J0_lag_3', 'J0_lag_4',\n",
    "       'J0_lag_5', 'J0_lag_6', 'J0_lag_7', 'C0_lag_1', 'C0_lag_2', 'C0_lag_3',\n",
    "       'C0_lag_4', 'C0_lag_5', 'C0_lag_6', 'C0_lag_7', 'Delta_C_lag_1',\n",
    "       'Delta_C_lag_2', 'Delta_C_lag_3', 'Delta_C_lag_4', 'Delta_C_lag_5',\n",
    "       'Delta_C_lag_6', 'Delta_C_lag_7', 'Delta_S_lag_1', 'Delta_S_lag_2',\n",
    "       'Delta_S_lag_3', 'Delta_S_lag_4', 'Delta_S_lag_5', 'Delta_S_lag_6',\n",
    "       'Delta_S_lag_7', 'Vavg_lag_1', 'Vavg_lag_2', 'Vavg_lag_3', 'Vavg_lag_4',\n",
    "       'Vavg_lag_5', 'Vavg_lag_6', 'Vavg_lag_7']\n",
    "for column in lagged_columns:\n",
    "    df[column]=df[column].abs()\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos los vectores de train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('is_fishing',axis=1)\n",
    "y = df['is_fishing']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=50)\n",
    "print(len(df[df['is_fishing']=='SI']))\n",
    "print(len(df[df['is_fishing']=='NO']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para evaluar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import matplotlib.pyplot as plt\n",
    "import tabulate\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "def evaluate_model(title,y_test, y_pred):\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    display(Markdown(title))\n",
    "    cmd_obj = ConfusionMatrixDisplay(cm, display_labels=['NO', 'SI'])\n",
    "    cmd_obj.plot()\n",
    "    cmd_obj.ax_.set(\n",
    "                    title='Matriz de confusi√≥n.', \n",
    "                    xlabel='Predict Values', \n",
    "                    ylabel='Actual Values')\n",
    "    plt.show()\n",
    "    _precision_score = precision_score(y_test, y_pred,pos_label='SI')\n",
    "    _recall_score = recall_score(y_test, y_pred, pos_label='SI')\n",
    "    _accuracy_score = accuracy_score(y_test, y_pred)\n",
    "    _f1_score = f1_score(y_test, y_pred, pos_label='SI')\n",
    "\n",
    "    data = [[\"Precision\",\"Recall\",\"Accuracy\",\"F1\"],\n",
    "            [\"%.2f\" % _precision_score, \"%.2f\" % _recall_score, \"%.2f\" % _accuracy_score, \"%.2f\" % _f1_score ]]\n",
    "    table = tabulate.tabulate(data, tablefmt='html')\n",
    "    display(table)\n",
    "    return _precision_score, _recall_score, _accuracy_score, _f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#extra_tree_classifier = ExtraTreeClassifier(random_state=1)\n",
    "#extra_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters={\"splitter\":[\"best\",\"random\"],\n",
    "            \"max_depth\" : [11,12,13,14,15,16,18,20],\n",
    "           \"min_samples_leaf\":[1,2,3,4,5,10],\n",
    "           \"min_weight_fraction_leaf\":[0, 0.1,0.2,0.4,0.6,0.8],\n",
    "           \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
    "           \"max_leaf_nodes\":[None,10,20,40,100,200,400] }\n",
    "\n",
    "grid = GridSearchCV(DecisionTreeClassifier(random_state=1), cv=3, n_jobs=-1, verbose=3,\n",
    "                    param_grid =parameters\n",
    "                    )\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Train Accuracy : %.3f'%grid.best_estimator_.score(X_train, y_train))\n",
    "print('Test Accuracy : %.3f'%grid.best_estimator_.score(X_test, y_test))\n",
    "print('Best Score Through Grid Search : %.3f'%grid.best_score_)\n",
    "print('Best Parameters : ',grid.best_params_)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=grid.best_params_['max_depth'], \n",
    "                            max_features=grid.best_params_['max_features'],\n",
    "                            max_leaf_nodes=grid.best_params_['max_leaf_nodes'],\n",
    "                            min_samples_leaf=grid.best_params_['min_samples_leaf'],\n",
    "                            min_weight_fraction_leaf=grid.best_params_['min_weight_fraction_leaf'],\n",
    "                            splitter=grid.best_params_['splitter']\n",
    ")\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "print('Best Parameters : ',grid.best_params_)\n",
    "dt_precision_score, dt_recall_score, dt_accuracy_score, dt_f1_score = evaluate_model('Arboles de decision optimizado',y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [12,13,14,15,16,17,18,20,25],\n",
    "    'max_features': [\"auto\", \"sqrt\", \"log2\"],\n",
    "    'min_samples_leaf': [1,2,3,4,5,6,7,8],\n",
    "    'min_samples_split': [2, 5 , 10,20],\n",
    "    'n_estimators': [100, 200,400,800,1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Train Accuracy : %.3f'%grid.best_estimator_.score(X_train, y_train))\n",
    "print('Test Accuracy : %.3f'%grid.best_estimator_.score(X_test, y_test))\n",
    "print('Best Score Through Grid Search : %.3f'%grid.best_score_)\n",
    "print('Best Parameters : ',grid.best_params_)\n",
    "\n",
    "dt = RandomForestClassifier(bootstrap=grid.best_params_['bootstrap'], \n",
    "                            max_depth=grid.best_params_['max_depth'],\n",
    "                            max_features=grid.best_params_['max_features'],\n",
    "                            min_samples_leaf=grid.best_params_['min_samples_leaf'],\n",
    "                            min_samples_split=grid.best_params_['min_samples_split'],\n",
    "                            n_estimators=grid.best_params_['n_estimators']\n",
    ")\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "rf_precision_score, rf_recall_score, rf_accuracy_score, rf_f1_score = evaluate_model('Random forest optimizado', y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_train_Scaled = preprocessing.scale(X_train)\n",
    "\n",
    "X_test_Scaled = preprocessing.scale(X_test)\n",
    "\n",
    "\n",
    "#parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],'C': [0.001, 0.10, 0.1, 10 ]},\n",
    "#              {'kernel': ['sigmoid'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],'C': [0.001, 0.10, 0.1, 10], 'coef0 ':[0,0.1,1]},\n",
    "#              {'kernel': ['linear'], 'C': [0.001, 0.10, 0.1, 1]}     \n",
    "#]\n",
    "\n",
    "parameters = [{'kernel': ['rbf'], 'gamma': [1e-2,1e-3,1e-4,1e-5,1e-6],'C': [0.001,0.01,0.1,1,10,100]},\n",
    "              {'kernel': ['sigmoid'], 'gamma': [1e-2,1e-3,1e-4,1e-5,1e-6],'C': [0.001,0.01,0.1,1,10,100],'coef0' : [0.01,0.1,1,10]},\n",
    "              {'kernel': ['linear'], 'C': [0.0001,0.001,0.01,0.1,1,10,100,1000]}\n",
    "              ]\n",
    "\n",
    "svm_precision_score_rbf=svm_recall_score_rbf=svm_accuracy_score_rbf=svm_f1_score_rbf=0\n",
    "svm_precision_score_sigmoid=svm_recall_score_sigmoid=svm_accuracy_score_sigmoid=svm_f1_score_sigmoid=0\n",
    "svm_precision_score_linear=svm_recall_score_linear=svm_accuracy_score_linear=svm_f1_score_linear=0\n",
    "\n",
    "\n",
    "for parameter in parameters:\n",
    "    \n",
    "    param_grid = parameter\n",
    "    grid = GridSearchCV(SVC(), param_grid, n_jobs = -1, verbose = 3)\n",
    "    grid.fit(X_train_Scaled, y_train)\n",
    "    kernel_str = parameter['kernel'][0]\n",
    "    y_pred = grid.predict(X_test_Scaled)\n",
    "    dt = grid\n",
    "\n",
    "    \n",
    "    print('Train Accuracy : %.3f'%grid.best_estimator_.score(X_train, y_train))\n",
    "    print('Test Accuracy : %.3f'%grid.best_estimator_.score(X_test, y_test))\n",
    "    print('Best Score Through Grid Search : %.3f'%grid.best_score_)\n",
    "    print('Best Parameters : ',grid.best_params_)\n",
    "\n",
    "    if parameter['kernel'][0] == 'rbf':\n",
    "        svm_precision_score_rbf, svm_recall_score_rbf, svm_accuracy_score_rbf, svm_f1_score_rbf = evaluate_model(kernel_str, y_test, y_pred)\n",
    "    if parameter['kernel'][0] == 'sigmoid':\n",
    "        svm_precision_score_sigmoid, svm_recall_score_sigmoid, svm_accuracy_score_sigmoid, svm_f1_score_sigmoid = evaluate_model(kernel_str, y_test, y_pred)\n",
    "    if parameter['kernel'][0] == 'linear':\n",
    "        svm_precision_score_linear, svm_recall_score_linear, svm_accuracy_score_linear, svm_f1_score_linear = evaluate_model(kernel_str, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna  # pip install optuna\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    param_grid = {\n",
    "        # \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 1023, step=10),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.0, 10),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.0, 100),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model = lgb.LGBMClassifier(objective=\"binary\", **param_grid)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            eval_metric=\"binary_logloss\",\n",
    "            #eval_metric=\"auc\",\n",
    "            early_stopping_rounds=100,\n",
    "            callbacks=[\n",
    "                #LightGBMPruningCallback(trial, \"auc\")\n",
    "                LightGBMPruningCallback(trial, \"binary_logloss\")\n",
    "            ],  # Add a pruning callback\n",
    "        )\n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_scores[idx] = log_loss(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\n",
    "\n",
    "#AUC -> maximixe\n",
    "#study = optuna.create_study(direction=\"maximize\", study_name=\"LGBM Classifier\")\n",
    "func = lambda trial: objective(trial, X, y)\n",
    "study.optimize(func, n_trials=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(objective=\"binary\", **study.best_params)\n",
    "model = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            eval_metric=\"binary_logloss\",\n",
    "            #eval_metric=\"auc\",\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=0\n",
    "            \n",
    "        )\n",
    "y_pred = model.predict(X_test)\n",
    "lgbm_precision_score_auc, lgbm_recall_score_auc, lgbm_accuracy_score_auc, lgbm_f1_score_auc = evaluate_model('lgbm grid search', y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "md(f'''| Algorithm     | Precision     | Recall        | Accuracy      | F1            |\n",
    "| ------------- | ------------- | ------------- | ------------- | ------------- |\n",
    "| Arboles de decision  |{dt_precision_score:.3f}|\t{dt_recall_score:.3f}|\t{dt_accuracy_score:.3f}|\t{dt_f1_score:.3f}|\n",
    "|Random Forest       |{rf_precision_score:.3f} |\t{rf_recall_score:.3f}|\t{rf_accuracy_score:.3f}|\t{rf_f1_score:.3f}|\n",
    "|    SVM_sigmoid        | {svm_precision_score_sigmoid:.3f} |\t{svm_recall_score_sigmoid:.3f}|\t{svm_accuracy_score_sigmoid:.3f}|\t{svm_f1_score_sigmoid:.3f}|\n",
    "|    SVM_rbf        | {svm_precision_score_rbf:.3f} |\t{svm_recall_score_rbf:.3f}|\t{svm_accuracy_score_rbf:.3f}|\t{svm_f1_score_rbf:.3f}|\n",
    "|    SVM_rbf        | {svm_precision_score_linear:.3f} |\t{svm_recall_score_linear:.3f}|\t{svm_accuracy_score_linear:.3f}|\t{svm_f1_score_linear:.3f}|\n",
    "| LightGBM_optuna      |{lgbm_precision_score_auc:.3f}|\t{lgbm_recall_score_auc:.3f}|\t{lgbm_accuracy_score_auc:.3f}|\t{lgbm_f1_score_auc:.3f}|\n",
    "'''\n",
    "       )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8a79dfa68d3b59c718a5e00f96adc917a1b17d46c628831ab97d3d56be05add"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
